# -*- coding: utf-8 -*-
"""Resume Matching with Job Descriptions Using PDF CVs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LIZUGZ-lGD52c3aa_HnzJv2XkQmKYut6

#**Objective**:
 Build a PDF extractor to pull relevant details from CVs in PDF format, and match them against the job descriptions from the Hugging Face dataset.

 `` Building a PDF extractor to pull relevant details from CVs in PDF format and match them against job descriptions from the Hugging Face dataset is a complex project that involves several steps. Below is a high-level outline of how you can approach this project: ``

# **Steps to build Model:**

#A.PDF Data Extraction
**Objective: Extract details from CVs in PDF format.**

Extracting details from CVs in PDF format is a common task in various applications, including recruitment and data analysis. Here's a simplified step-by-step guide on how to extract details from CVs in PDF format using Python:
"""

pip install PyPDF2

"""#  1.Data Collection:
* Obtain a dataset of CVs in PDF format. I can use publicly available datasets or collect CVs from various sources.
* Download the Hugging Face dataset containing job descriptions or scrape job descriptions from job boards or company websites.
"""

import PyPDF2

def extract_text_from_pdf(pdf_file_path):
    text = ""
    try:
        # Open the PDF file in binary mode
        with open(pdf_file_path, 'rb') as pdf_file:
            # Create a PDF reader object
            pdf_reader = PyPDF2.PdfFileReader(pdf_file)

            # Iterate through each page
            for page_num in range(pdf_reader.numPages):
                # Extract text from the current page
                page = pdf_reader.getPage(page_num)
                text += page.extractText()

    except Exception as e:
        print(f"Error: {str(e)}")

    return text

if __name__ == "__main__":
    pdf_file_path = "/content/Resume.pdf"  # path of  PDF file
    extracted_text = extract_text_from_pdf(pdf_file_path)

    # Print the extracted text
    print(extracted_text)

"""# To install PDFMiner, we can use pip:"""

pip install pdfminer.six

from pdfminer.high_level import extract_text

def extract_text_from_pdf(pdf_file_path):
    text = ""
    try:
        text = extract_text(pdf_file_path)

    except Exception as e:
        print(f"Error: {str(e)}")

    return text

if __name__ == "__main__":
    pdf_file_path = "/content/Resume.pdf"  # path of PDF file
    extracted_text = extract_text_from_pdf(pdf_file_path)

    # Print the extracted text
    print(extracted_text)

""" # 2.Data Preprocessing:

* Convert the PDFs to text. We can use Python libraries like PyPDF2 or pdfplumber for this purpose.
* Clean and preprocess the text data to remove noise, such as special characters and unnecessary formatting.
"""



#Text Preprocessing:
#Clean and preprocess the extracted text to remove unwanted characters, formatting, or noise. We can use regular expressions and string manipulation for this step

import re

def clean_text(text):
    # Remove extra whitespaces, line breaks, and special characters
    cleaned_text = re.sub(r'\s+', ' ', text)
    cleaned_text = re.sub(r'[^\x00-\x7F]+', '', cleaned_text)
    return cleaned_text

"""#3.Information Extraction:

* Use Natural Language Processing (NLP) techniques to extract relevant details from CVs, such as:
* Name
* Contact Information (phone number, email)
* Education History (universities, degrees, graduation dates)
* Work Experience (job titles, companies, dates)
* Skills and Keywords
* Awards and Certifications
"""

#Information Extraction:
#Extract specific details from the cleaned text using regular expressions or custom parsing rules. For example, we can extract names, contact information, education history, work experience, and skills.

def extract_Category(text):
    # Implement a pattern or rule to extract names
    pass

def extract_education_info(text):
    pass
    # Implement a pattern or rule to extract education information

def extract_skills_info(text):
    pass
    # Implement a pattern or rule to extract skills information

"""#B. **Job Description Data Understanding**
**Objective: Fetch and comprehend job descriptions from the Hugging Face dataset.**

* Dataset: https://huggingface.co/datasets/jacob-hugging-face/job-descriptions/viewer/default/train?row=0

To fetch and comprehend job descriptions from the Hugging Face dataset using the Hugging Face datasets library
"""

pip install datasets

"""Now, I  am use Python to fetch and understand job descriptions from the Hugging Face dataset:"""

from datasets import load_dataset

# Load the Hugging Face dataset
dataset = load_dataset("jacob-hugging-face/job-descriptions")

# Extract 10-15 job descriptions
num_descriptions_to_extract = 15
job_descriptions = dataset["train"]["job_description"][:num_descriptions_to_extract]

# Print the job descriptions
for idx, description in enumerate(job_descriptions):
    print(f"Job Description {idx + 1}:")
    print(description)
    print("=" * 50)

"""# **C. Candidate-Job Matching**
**Objective: Match extracted CV details against the fetched job descriptions based on skills and education.**

Tools Suggested: Use the Transformers library by Hugging Face. BERT or DistilBERT can be a starting point for embedding extraction.

```To achieve my objective of matching extracted CV details against fetched job descriptions based on skills and education using the Transformers library by Hugging Face, I can follow these steps:```

# Data Collection and Preprocessing:

* Gather a dataset of CVs and job descriptions. I need labeled data where each CV is associated with a job description that indicates whether it's a suitable match or not.
* Preprocess the text data by tokenizing it into appropriate input format for the chosen Transformer model (e.g., BERT or DistilBERT).

# 1: Preprocess CV Details and Job Descriptions
Before matching, I need to preprocess both the CV details and job descriptions. Preprocessing may include tokenization, lowercasing, and handling special characters.
"""

pip install transformers

"""# 2.Fine-Tuning a Pretrained Transformer Model:

* Choose a pretrained transformer model (e.g., BERT or DistilBERT) that has  
  been pretrained on a large corpus of text data. I can use the Hugging Face
   Transformers library to load these models.
* Fine-tune the transformer model for my specific task, which is matching CVs to job descriptions. I'll need to design a suitable architecture for this, typically involving adding classification layers on top of the pretrained model.
* Train the model using my labeled dataset. Monitor its performance using appropriate evaluation metrics (e.g., accuracy, F1-score)
"""

import torch
from transformers import DistilBertTokenizer, DistilBertModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

"""#3. Feature Extraction:

For both the CVs and job descriptions, use the fine-tuned transformer model to extract embeddings. These embeddings will represent the textual content of each document.
Store the embeddings in a suitable format for easy retrieval and comparison
"""

from transformers import DistilBertTokenizer

tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")

"""#4. Matching Process:

* To match CVs against job descriptions based on skills and education, I can use various methods:
* Cosine Similarity: Compute the cosine similarity between the embeddings of each CV and job description. This will give you a similarity score, and I can set a threshold to determine whether they are a match.
* Machine Learning Models: Train a machine learning model (e.g., logistic regression, support vector machine) using the embeddings as features and the labeled data as the target variable.
* Natural Language Processing Techniques: Use natural language processing techniques such as Named Entity Recognition (NER) to extract specific skills and education information from both CVs and job descriptions. Then, compare the extracted information to find matches.
"""

# CV details and job description (I'll replace these with my data)
cv_details = "Experienced software engineer with expertise in Python and machine learning."
job_description = "We are looking for a software engineer proficient in Python and machine learning."

# Tokenize CV details and job description
cv_tokens = tokenizer(cv_details, return_tensors="pt", padding=True, truncation=True)
job_tokens = tokenizer(job_description, return_tensors="pt", padding=True, truncation=True)

# Sample CV and job description text
cv_text = "I have a Bachelor's degree in Computer Science and extensive experience with Python programming. I am skilled in machine learning and natural language processing."
job_description = "We are looking for a Data Scientist with a strong background in machine learning, Python programming, and a Bachelor's degree in Computer Science."

# Load DistilBERT tokenizer and model
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertModel.from_pretrained('distilbert-base-uncased')

# Tokenize and encode CV and job description
cv_tokens = tokenizer.encode(cv_text, add_special_tokens=True, max_length=512, truncation=True, padding=True, return_tensors='pt')
job_tokens = tokenizer.encode(job_description, add_special_tokens=True, max_length=512, truncation=True, padding=True, return_tensors='pt')

# Get embeddings for CV and job description
with torch.no_grad():
    cv_embeddings = model(cv_tokens)[0].mean(dim=1)  # Mean pooling of token embeddings
    job_embeddings = model(job_tokens)[0].mean(dim=1)

# Compute cosine similarity between CV and job description embeddings
similarity_score = cosine_similarity(cv_embeddings, job_embeddings)[0][0]

"""# 5.Threshold Setting:

* Decide on an appropriate threshold for similarity or classification scores to determine whether a CV matches a job description. This threshold should be chosen based on your dataset and desired trade-off between precision and recall.
"""

# Define a similarity threshold to determine if it's a match
similarity_threshold = 0.75

"""#  **CV matches the job description:-**"""

# Check if the CV matches the job description based on the similarity score
if similarity_score >= similarity_threshold:
    print("CV and job description match!")
else:
    print("CV and job description do not match.")